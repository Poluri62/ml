{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87445c6c",
   "metadata": {},
   "source": [
    "# Implementing Stochastic Gradient Descent on LTU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f531a",
   "metadata": {},
   "source": [
    "A Linear Threshold Unit(LTU) is a simple artificial neuron whose output is the thresholded  weighted sum of its inputs. What does that mean?<br><br> \n",
    "Let x1,x2,x3 be the inputs to the LTU.<br>\n",
    "For some arbitrary weights (w1,w2,w3), the weighted sum of these inputs would be calculated as <strong>w1x1 + w2x2 + w3x3</strong>.\n",
    "If <strong>T</strong> is the threshold of the LTU, then<br><br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "+1, \n",
    "&emsp;&emsp;\n",
    "if w1x1 + w2x2 + w3x3 >= T<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; \n",
    "h(x) = <br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "-1, \n",
    "&emsp;&emsp;otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4de7f",
   "metadata": {},
   "source": [
    "If a set of points can be seperated by a linear decision boundary(or a hyperplane in multiple dimensions), then they are said to be <strong>linearly seperable</strong>. For example, the AND,OR or NAND gates can have 0s and 1s seperated by a line. On the other hand, XOR is not linearly seperable.<br>\n",
    "\n",
    "LTUs can be used to represent such linearly seperable classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e7b91",
   "metadata": {},
   "source": [
    "### Training to learn the weights for AND Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c7fd1",
   "metadata": {},
   "source": [
    "Consider four input features(x1,x2,x3,x4). The AND Gate is represented as  x1 ∧ x2 ∧ x3 ∧ x4 <=> y , i.e, y is  true iff all the inputs are true.<br>\n",
    "<strong>Goal:</strong> to learn the weights of a function represented by an LTU that approximates an AND gate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d6cdc",
   "metadata": {},
   "source": [
    "### Using MSE as the Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d64f46",
   "metadata": {},
   "source": [
    "In order to do some learning, we need a loss function against which the algorithm calculates the loss and performs gradient descent to find the local minima.<br>\n",
    "For one training example:<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "Cost, J[i] = ( y_true[i] - y_pred[i] )^2<br><br>\n",
    "The gradient (dJ[i]/dw) for the ith example and jth feature will be<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "             dJ[i]/dw[j] = -2 * (y[i] - y_pred[i]) * x[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5a6b5",
   "metadata": {},
   "source": [
    "<strong>Stoachastic Gradient Descent Algorithm</strong> <br>\n",
    " &emsp;Repeat\n",
    "<br>\n",
    "&emsp;&emsp;  for each training example i:\n",
    "<br>\n",
    "&emsp;&emsp;&emsp;&emsp;Compute hx(x[i],w) as y_hat\n",
    "<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;for each feature j:\n",
    "<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;g[j] = -2 * (y[i] - y_hat) * x[i][j]\n",
    "<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;w[j] = w[j] - learning_rate * g[j]\n",
    "<br>\n",
    "<br>\n",
    "The overall gradient is approximated by the gradient from each training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "eda8c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "00f0bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " hx is the thresholded weighted sum. The threshold we have chosen is 1 (this is a hyperparameter)\n",
    " The method takes two parameters:\n",
    "    x: one input value of shape (4,1) [since we have 4 features]\n",
    "    w: weight vector of shape (4,1)  [since each feature requires a corresponding weight]\n",
    "'''\n",
    "def hx(x,w): \n",
    "    u = np.dot(w.T, x)   \n",
    "    if u>=1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\"\"\"\n",
    " SGD_mse performs stochastic gradient descent using mean squred error as the Loss function. \n",
    "\n",
    " The method takes the followinf input parameters:\n",
    "     X:             input matrix of shape (16,4,1) since we have 16 training examples, and each input is of shape (4,1)\n",
    "     y:             output vector of shape (16,1) corresponding to 0/1 for each training example\n",
    "     w:             weight vector of shape (4,1)\n",
    "     alpha:         learning rate\n",
    "     num_examples:  number of training examples\n",
    "     num_features:  number of features in the input\n",
    "     iterations:    number of iterations to run the gradient descent algorithm\n",
    "     \n",
    " This method updates the weight vector w\n",
    "\n",
    "\"\"\"\n",
    "def SGD_mse(X, y, w, alpha, num_examples, num_features, iterations):\n",
    "    for iter in range(iterations):\n",
    "        g = np.zeros((num_features, 1))\n",
    "        for i in range(num_examples):\n",
    "            y_hat = hx(X[i],w)\n",
    "            for j in range(num_features):\n",
    "                g[j] = -2 * (y[i] - y_hat) * X[i][j]\n",
    "                w[j] -= alpha*g[j]\n",
    "    print(\"\\nAfter learning, w: \\n\",w)\n",
    "        \n",
    "\n",
    "#Helper function to compare true and predicted values                \n",
    "def validate(X,Y_true,w):\n",
    "    for i in range(X.shape[0]):\n",
    "        y_hat = hx(X[i],w)\n",
    "        print(\"True: \",Y[i], \"\\tPredicted: \",y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "85eeebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2  x3  x4  y\n",
      "0   0   0   0   0  0\n",
      "1   0   0   0   1  0\n",
      "2   0   0   1   0  0\n",
      "3   0   0   1   1  0\n",
      "4   0   1   0   0  0\n"
     ]
    }
   ],
   "source": [
    "#import the data using Pandas\n",
    "data_df = pd.read_csv(\"data.csv\")\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "f13fef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  [[0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 1 1]\n",
      " [1 0 0 0]\n",
      " [1 0 0 1]\n",
      " [1 0 1 0]\n",
      " [1 0 1 1]\n",
      " [1 1 0 0]\n",
      " [1 1 0 1]\n",
      " [1 1 1 0]\n",
      " [1 1 1 1]]\n",
      "Y:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data_df[['x1','x2','x3','x4']])\n",
    "Y = np.array(data_df['y'])\n",
    "\n",
    "print(\"X: \",X)\n",
    "print(\"Y: \",Y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "5a106e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially, weight vector w: \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "num_examples = X.shape[0]\n",
    "num_features = X.shape[1]\n",
    "\n",
    "w = np.zeros((num_features,1))\n",
    "print(\"Initially, weight vector w: \\n\",w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "abd4ffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After learning, w: \n",
      " [[0.4]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]]\n"
     ]
    }
   ],
   "source": [
    "#Calling the SGD_mse method for learning\n",
    "SGD_mse(X,Y,w,0.1,num_examples, num_features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "c91b7e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  0 \tPredicted:  0\n",
      "True:  1 \tPredicted:  1\n"
     ]
    }
   ],
   "source": [
    "#Validating\n",
    "validate(X,Y,w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
